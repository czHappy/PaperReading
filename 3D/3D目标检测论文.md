# 3D目标检测-CVPR2021

## 3D目标检测的主要方法

1. **直接法**直接从图像估计3D检测，而无需预测中间3D场景表示； 他们可以结合2D图像平面和3D空间之间的几何关系来辅助检测。
2. **基于深度法**使用逐像素深度图作为附加输入来执行3D检测任务，其中深度图是使用单目深度估计架构预先计算的； 估计的深度图可以与图像结合使用以执行3D检测任务。
3. **基于网格法**避免了通过预测BEV网格表示来估计原始深度值，而将其用作3D检测架构的输入； 可以将多个体素投影到同一图像特征，从而导致沿着投影射线的重复特征并降低检测精度。

## CVPR-2021

### ***3DIoUMatch: Leveraging IoU Prediction for Semi-Supervised 3D Object Detection***

- 思路：3D检测需要大量标注数据——引入3D半监督学习，利用未标注数据生成伪标签——发现伪标签存在噪音——提出confidence-based过滤机制进行筛选——进一步发现该方法不能保证定位质量，又提出3D IoU 进行度量

- 使用ScanNet、SUN-RGBD、KITTI等数据集训练，无法适用于单目RGB

### **Categorical Depth Distribution Network for Monocular 3D Object Detection**

- 思路：提出了一个单目3D目标检测方法，*CaDDN*，它可以通过学习分类的深度分布来得到准确的3D检测。利用概率深度估计，*CaDDN*能够以端到端的方式从图像生成高质量的鸟瞰特征(BEV )表示。
  - 预测按像素分类的深度分布来准确在3D空间里定位图片信息。每一个预测的分布描述了一个像素属于一组预定义的depth bins的概率。
  - 学习深度分布以一个端到端的方式，联合优化准确的深度预测和准确的3D目标检测。
- 在KITTI 3D目标检测测试基准的汽车和行人类别中，*CaDDN*在所有先前发布的单目方法中排名第一。

- 开源代码：无

### **ST3D: Self-training for Unsupervised Domain Adaptation on 3D Object Detection**

- 无监督domain adaptive的自学习3D目标检测方法，基于点云。



### CenterPoint: Center-based 3D Object Detection and Tracking 

- 将CenterNet用到了基于点云的三维目标检测问题上，证明Anchor Free的这种方法应用在基于点云的三维目标检测任务中也是可行的。主要是两阶段方法：
  - CenterPoint首先利用基于keypoint的检测器来检测物体的中心，并回归出其他属性，包括3D size，3D orientation，和速度。
  - refine the estimates result，利用物体上额外的点云数据。

- 基于点云

### Objects are Different: Flexible Monocular 3D Object Detection

- 提出了一个灵活的**单目三维目标检测框架**，该框架对目标进行显示解耦，并自适应地结合多种目标深度估计方法。具体地说，是将特征映射的边缘解耦以预测长尾截断对象，从而不影响政策对象的优化。此外，将目标深度估计公式化为直接回归目标深度和从不同关键点组求解深度的不确定性引导集合。
- 关键点估计,采取10个关键点：8个顶点+1个顶面中心+1个底面中心

- 模型

  ![](https://img-blog.csdnimg.cn/20210518200100313.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyMDk3NTc3,size_16,color_FFFFFF,t_70#pic_center)

- code:https://github.com/zhangyp15/MonoFlex
- 实时性：未知

### M3DSSD: Monocular 3D Single Stage Object Detector

- 思路：图像经过Backbone（DLA-102）网络首先输出每个anchor的类别以及置信度（confidence），Shape Align模块依据置信度最大的anchor调整后续卷积层的感受野，并进一步输出2D与3D框的中心点位置，Center Align模块利用2D与3D框中心点位置，做feature层面的中心点特征对齐，对齐之后的特征分别用于输出2D的高和宽以及3D的长宽高以及朝向角，object的深度则经过ANAB模块利用全局信息后进行输出。

- 模型

  ​	![](https://pic3.zhimg.com/80/v2-8a339994bcd2a233b1ca53e5ac54dd06_1440w.jpg)

- code:无

### MonoRUn: Monocular 3D Object Detection by Self-Supervised Reconstruction and Uncertainty Propagation

-  MonoRUn是一种新颖的检测框架，可以通过在每个预测的2D框内的感兴趣区域（RoI）上附加一个3D分支来扩展现成的2D检测器，3D分支对RoI中密集的三维物体坐标进行回归，建立几何关系和目标的2D-3D对应关系。通过标签物体姿态和相机内部参数，将预测的三维坐标投影回图像中。

- 模型

  ![](https://d3i71xaburhd42.cloudfront.net/81a218dd3cacd34b470dcb48f394c5a72b6cdd65/3-Figure2-1.png)

- 实时性：未知
- code: https://github.com/tjiiv-cprg/MonoRUn



### GrooMeD-NMS: Grouped Mathematically Differentiable NMS for Monocular 3D Object Detection

- 提出并集成GrooMeD-NMS--一种新颖的分组数学可区分的NMS，用于单眼3D物体检测，在KITTI基准数据集上实现了最先进的单目3D物体检测结果，表现与基于单眼视频的方法相当。

- code: https://github.com/abhi1kumar/groomed_nms

- 模型

  ![](https://github.com/abhi1kumar/groomed_nms/raw/main/images/groomed_nms.png)

- 实时性：未知


