<!DOCTYPE html>
<html>
<head>
<title>Improved Image Matting via Real-time User Clicks and Uncertainty Estimation.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="improved-image-matting-via-real-time-user-clicks-and-uncertainty-estimation">Improved Image Matting via Real-time User Clicks and Uncertainty Estimation</h1>
<h2 id="%E8%AE%BA%E6%96%87%E4%BF%A1%E6%81%AF">论文信息</h2>
<ul>
<li>会议：CVPR 2021</li>
<li>作者：Tianyi Wei, Dongdong Chen2, Wenbo Zhou, et al.</li>
<li>论文地址：https://arxiv.org/abs/2012.08323</li>
</ul>
<h2 id="%E5%88%9B%E6%96%B0%E7%82%B9">创新点</h2>
<h3 id="user-click-vs-trimap-based-and-trimap-free">user click VS. trimap-based and trimap-free</h3>
<ul>
<li>
<p>基于trimap和无trimap的方法都有各自的优缺点。具体来说，基于trimap的方法可以实现最先进的性能，但它们需要用户提供绘制良好的trimap来指示前景、背景和过渡区域。trimap-free方法不需要任何用户，但它们的性能明显更差。这是因为，如果没有先验，这样的方法经常会含糊不清哪些是目标前景对象，特别是在一些复杂的情况下。</p>
</li>
<li>
<p>为了解决模糊问题，一个典型的解决方案是为一个感兴趣的类别收集一个大规模的有标签的数据集，这样网络就可以依靠语义来识别前景。
然而，数据标记很昂贵，而且它不能扩展到除特定以外的类别，例如下图第一个案例中的“surfboard”。此外，即使是某一特定类别，在某些情况下也不能满足用户的需求。例如第二种情况中，用户可能只想保留其中一个目标画像。
<img src="img/1.png" alt=""></p>
</li>
<li>
<p>本文首次尝试使用简单的用户点击作为抠图先验,这种更简单的用户先验，它足以用最小的努力识别前景对象，使得用户体验大大提升。该方法精度优于trimap-free方法并能与trimap-based方法相比较。</p>
</li>
</ul>
<h3 id="uncertainty-estimation-module">uncertainty estimation module</h3>
<ul>
<li>引入了一个新颖的不确定性估计模块，可以自动预测哪些局部需要polish，用户可以灵活选择改进哪些部分</li>
<li>引入一个uncertainty-guided local refinement network，通过之前阶段产生的uncertainty map作为提示，可以输出更多细节和消除artifacts。</li>
</ul>
<h2 id="%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84">整体架构</h2>
<ul>
<li>用户可以选择两种提示方式，当用户点击图像某处时并选择前景模式时，一个半径为r的圆形区域将会在与原图等大小的二维矩阵heatmap U中被赋值为1，选择背景模式则赋值为-1， 不做操作则为0.</li>
<li>将原图与用户提示heatmap U 输入encoder中，然后将结果送入两个decoder。alpha decoder负责产生一个原始的alpha matte；uncertainty decoder产生uncertainty map，从而得到alpha matting network对哪些区域是不够自信的，值较高的点周围k*k(default k = 64)的patch会被裁剪下来(原图和之前得到的alpha matte)送入 refinement模块得到refined alpha matte patch补到原始alpha matte之中。
<img src="img/2.png" alt=""></li>
</ul>
<h2 id="%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0">损失函数</h2>
<h3 id="matting-network-loss">Matting Network Loss</h3>
<ul>
<li>
<p>image space regression loss
$$\mathcal{L}<em>{r e g}=\frac{1}{|T|} \sum</em>{i \in T}\left|\alpha_{p}^{i}-\alpha_{g}^{i}\right|+\frac{1}{|S|} \sum_{j \in S}\left(\alpha_{p}^{j}-\alpha_{g}^{j}\right)^{2}$$</p>
</li>
<li>
<p>gradient loss，有助于网络产生更加锐利的结果 shaper
$$
\mathcal{L}<em>{\text {grad }}=\frac{1}{|I|} \sum</em>{i \in \Omega}\left|\nabla\left(\alpha_{p}^{i}\right)-\nabla\left(\alpha_{g}^{i}\right)\right|
$$</p>
</li>
</ul>
<h3 id="uncertainty-estimation-module-loss">Uncertainty Estimation Module Loss</h3>
<ul>
<li>从概率论的对alpha matte prediction建模，可以将其看成是一种参数分布
$$
p(\alpha \mid I, U ; \mathcal{D})
$$</li>
<li>作者默认将其看为单变量拉普拉斯分布，其中$\mu$就是目标alpha matte $\alpha_p$, $\sigma$就是uncertainty decoder输出的$\sigma_p$
$$
f(x \mid \mu, \sigma)=\frac{1}{2 \sigma} e^{-\frac{|x-\mu|}{\sigma}}
$$</li>
<li>从而可以使用最大似然估计法来对该分布进行参数估计，体现在损失函数上就可以使用负对数来minimize
$$
\mathcal{L}<em>{u e}=-\log p(\alpha \mid I, U ; D)=\frac{1}{|\mathcal{N}|} \sum</em>{I \in \mathcal{D}}\left(\log \sigma_{p}+\frac{\left|x-\alpha_{p}\right|}{\sigma_{p}}\right)
$$</li>
</ul>
<h3 id="local-refinement-network-loss">Local Refinement Network Loss</h3>
<ul>
<li>patch中大多数像素已经是正确的了，预测错误的像素占比很少，作者认为这些hard pixels需要更强的优化，故而提出了hard-sample mining目标函数，对top20%误差的像素进行额外损失加成
$$
\mathcal{L}<em>{\text {refine }}=\frac{1}{|C|} \sum</em>{i \in C}\left|\alpha_{p}^{i}-\alpha_{g}^{i}\right|+\lambda \frac{1}{|H|} \sum_{j \in H}\left|\alpha_{p}^{j}-\alpha_{g}^{j}\right|
$$</li>
</ul>
<h3 id="%E8%AE%AD%E7%BB%83%E7%BB%86%E8%8A%82">训练细节</h3>
<ul>
<li>首先单独训练matting network部分，待其收敛后，将其freeze后训练uncertainty estimation decoder.
<ul>
<li>训练matting network时，为了让其适应用户点击行为，作者使用模拟用户交互的办法，对每张图片随机采样总数为m次点击操作，半径r=15,其中m满足参数为1/6的几何分布。</li>
</ul>
</li>
<li>训练refine network时，先用matting network去预测数据集的alpha matte，然后计算误差绝对值，选取其中最具有挑战性的patches进作为训练样本</li>
</ul>
<h3 id="%E5%AE%9E%E4%BE%8B">实例</h3>
<ul>
<li>https://www.youtube.com/watch?v=pAXydeN-LpQ</li>
</ul>
<h2 id="%E4%B8%80%E4%BA%9B%E7%96%91%E6%83%91">一些疑惑</h2>
<ul>
<li>matting阶段ground truth问题
<ul>
<li>作者训练阶段生成的用户点击是随机在图片中点击的，每张图片点击次数m满足参数为1/6的几何分布，此时网络输入是(I,U)，输出是$\alpha_p$,其所对应的GT应该依赖于U（否则无法达到作者所说的能够使用U来控制输出前景，包括出现一些数据集中未出现的类以及擦去同类别目标画像中的一个），但又无法预先生成每个U所对应的GT，因为U是训练时随机生成的</li>
</ul>
</li>
</ul>
<p><img src="img/3.png" alt=""></p>

</body>
</html>
